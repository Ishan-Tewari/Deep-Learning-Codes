{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# UNET","metadata":{}},{"cell_type":"markdown","source":"## Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, concatenate, Lambda\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Getting Training and Testing Image","metadata":{}},{"cell_type":"code","source":"import os\n\ntrain_images = []\nfor dirname, _, filenames in os.walk('/kaggle/input/dataset/dataset1/images_prepped_train'):\n    for filename in filenames:\n        train_images.append(os.path.join(dirname, filename))\n\ntest_images = []\nfor dirname, _, filenames in os.walk('/kaggle/input/dataset/dataset1/images_prepped_test'):\n    for filename in filenames:\n        test_images.append(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Defining our UNET Model along with VGG Encoder","metadata":{}},{"cell_type":"code","source":"batch_size = 2\nnepochs = 5\nnclasses = 12\n\n\ndef unet_with_vgg_encoder():\n    \n    # taking vgg16 pretrained model without top\n    pretrained_model = VGG16(include_top=False, weights='imagenet', \n                            input_shape=(360, 480, 3))\n    pretrained_model.summary()\n    \n    # taking input layer for the pretrained model\n    input_layer = pretrained_model.input\n    \n    # fetching output of the 6th layer from the last\n    output_layer_pretrained = pretrained_model.layers[-6].output\n    encoder = Model(input_layer, output_layer_pretrained)\n    \n    # encoder is model with given input layer and output layer\n    # we are setting trainable=false for all layers of encoder model\n    for i in encoder.layers:\n        i.trainable=False\n        \n    encoder.summary()\n    \n    # convolutional block 1\n    lastPooling = MaxPooling2D(pool_size=(2, 2), padding='same')(output_layer_pretrained)\n    center = Conv2D(1024, (3, 3), activation='relu', padding='same')(lastPooling)\n    center = Conv2D(1024, (3, 3), activation='relu', padding='same')(center)\n    center = BatchNormalization()(center)\n    \n    # convolutional block 2\n    up4 = UpSampling2D((2, 2))(center)\n    up4 = Conv2D(512, (2, 2), activation='relu', padding='same')(up4)\n    up4 = Lambda(lambda x: x[:, 0:45, :, :])(up4)\n    up4 = concatenate([up4, encoder.get_layer(name='block4_conv3').output], axis=3)\n    up4 = Conv2D(512, (3, 3), activation='relu', padding='same')(up4)\n    up4 = Conv2D(512, (3, 3), activation='relu', padding='same')(up4)\n    up4 = Conv2D(512, (3, 3), activation='relu', padding='same')(up4)\n    up4 = BatchNormalization()(up4)\n    \n    # convolutional block 3\n    up3 = UpSampling2D((2, 2))(up4)\n    up3 = Conv2D(256, (2, 2), activation='relu', padding='same')(up3)\n    up3 = concatenate([up3, encoder.get_layer(name='block3_conv3').output], axis=3)\n    up3 = Conv2D(256, (3, 3), activation='relu', padding='same')(up3)\n    up3 = Conv2D(256, (3, 3), activation='relu', padding='same')(up3)\n    up3 = Conv2D(256, (3, 3), activation='relu', padding='same')(up3)\n    up3 = BatchNormalization()(up3)\n    \n    # convolutional block 4\n    up2 = UpSampling2D((2, 2))(up3)\n    up2 = Conv2D(128, (2, 2), activation='relu', padding='same')(up2)\n    up2 = concatenate([up2, encoder.get_layer(name='block2_conv2').output], axis=3)\n    up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n    up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n    up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n    up2 = BatchNormalization()(up2)\n    \n    # convolutional block 5\n    up1 = UpSampling2D((2, 2))(up2)\n    up1 = Conv2D(64, (2, 2), activation='relu', padding='same')(up1)\n    up1 = concatenate([up1, encoder.get_layer(name='block1_conv2').output], axis=3)\n    up1 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n    up1 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n    up1 = Conv2D(nclasses, (1, 1), activation='softmax', padding='same')(up1)\n    \n    model = Model(inputs=input_layer, outputs=up1)\n    model.summary()\n    return model\n","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Defining the training and the testing generators","metadata":{}},{"cell_type":"markdown","source":"**Training Generator**","metadata":{}},{"cell_type":"code","source":"# defining traingenerator function to fetch training images and their masks from the dataset\n# using flow from dataframe\n\ndf = pd.DataFrame(train_images, columns=['image names'])\n\n\ndef traingenerator():\n    image_datagen = ImageDataGenerator(rescale=1/255)\n    mask_datagen = ImageDataGenerator()\n    image_batch_generator = image_datagen.flow_from_dataframe(df,\n                                                              directory='../input/dataset/dataset1/images_prepped_train',\n                                                              x_col='image names',\n                                                              class_mode=None,\n                                                              target_size=(360, 480),\n                                                              shuffle=False,\n                                                              seed=2019,\n                                                              batch_size=batch_size,\n                                                              color_mode='rgb')\n    \n    mask_batch_generator = mask_datagen.flow_from_dataframe(df,\n                                                            directory='../input/dataset/dataset1/annotations_prepped_train', \n                                                            x_col='image names',\n                                                            class_mode=None,\n                                                            target_size=(360, 480),\n                                                            shuffle=False,\n                                                            seed=2019,\n                                                            batch_size=batch_size,\n                                                            color_mode='grayscale')\n    \n    combined_generator = zip(image_batch_generator, mask_batch_generator)\n    \n    for (i, j) in combined_generator:\n        new_mask = np.zeros(shape=(j.shape[0], j.shape[1], j.shape[2], nclasses))\n        for k in range(j.shape[0]):\n            mask = j[k]\n            for m in range(nclasses):\n                new_mask[k, :, :, m] = mask[:, :, 0] == m\n        yield(i, new_mask)\n    ","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Testing Generator**","metadata":{}},{"cell_type":"code","source":"# defining testgenerator function to fetch testing images and their masks from the dataset\n# using flow from dataframe\n\ndf1 = pd.DataFrame(test_images, columns=['image names'])\n\n\ndef testgenerator():\n    image_datagen_test = ImageDataGenerator(rescale=1/255)\n    image_batch_generator_test = image_datagen_test.flow_from_dataframe(df1,\n                                                                        directory='../input/dataset/dataset1/images_prepped_test',\n                                                                        x_col='image names',\n                                                                        class_mode=None,\n                                                                        target_size=(360, 480),\n                                                                        shuffle=False,\n                                                                        seed=2019,\n                                                                        batch_size=batch_size,\n                                                                        color_mode='rgb')\n    for i in image_batch_generator_test:\n        yield i","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Combining everything to finally make our UNET Model","metadata":{}},{"cell_type":"code","source":"unet = unet_with_vgg_encoder()\nunet.compile(optimizer=keras.optimizers.Adam(lr=1e-4),\n             loss='categorical_crossentropy',\n            metrics=['accuracy'])\nunet.fit(traingenerator(), steps_per_epoch=400, epochs=nepochs)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 360, 480, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 360, 480, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 360, 480, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 180, 240, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 180, 240, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 180, 240, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 90, 120, 128)      0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 90, 120, 256)      295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 90, 120, 256)      590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 90, 120, 256)      590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 45, 60, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 45, 60, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 45, 60, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 45, 60, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 22, 30, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 22, 30, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 22, 30, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 22, 30, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 11, 15, 512)       0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 360, 480, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 360, 480, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 360, 480, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 180, 240, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 180, 240, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 180, 240, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 90, 120, 128)      0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 90, 120, 256)      295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 90, 120, 256)      590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 90, 120, 256)      590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 45, 60, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 45, 60, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 45, 60, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 45, 60, 512)       2359808   \n=================================================================\nTotal params: 7,635,264\nTrainable params: 0\nNon-trainable params: 7,635,264\n_________________________________________________________________\nModel: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 360, 480, 3) 0                                            \n__________________________________________________________________________________________________\nblock1_conv1 (Conv2D)           (None, 360, 480, 64) 1792        input_1[0][0]                    \n__________________________________________________________________________________________________\nblock1_conv2 (Conv2D)           (None, 360, 480, 64) 36928       block1_conv1[0][0]               \n__________________________________________________________________________________________________\nblock1_pool (MaxPooling2D)      (None, 180, 240, 64) 0           block1_conv2[0][0]               \n__________________________________________________________________________________________________\nblock2_conv1 (Conv2D)           (None, 180, 240, 128 73856       block1_pool[0][0]                \n__________________________________________________________________________________________________\nblock2_conv2 (Conv2D)           (None, 180, 240, 128 147584      block2_conv1[0][0]               \n__________________________________________________________________________________________________\nblock2_pool (MaxPooling2D)      (None, 90, 120, 128) 0           block2_conv2[0][0]               \n__________________________________________________________________________________________________\nblock3_conv1 (Conv2D)           (None, 90, 120, 256) 295168      block2_pool[0][0]                \n__________________________________________________________________________________________________\nblock3_conv2 (Conv2D)           (None, 90, 120, 256) 590080      block3_conv1[0][0]               \n__________________________________________________________________________________________________\nblock3_conv3 (Conv2D)           (None, 90, 120, 256) 590080      block3_conv2[0][0]               \n__________________________________________________________________________________________________\nblock3_pool (MaxPooling2D)      (None, 45, 60, 256)  0           block3_conv3[0][0]               \n__________________________________________________________________________________________________\nblock4_conv1 (Conv2D)           (None, 45, 60, 512)  1180160     block3_pool[0][0]                \n__________________________________________________________________________________________________\nblock4_conv2 (Conv2D)           (None, 45, 60, 512)  2359808     block4_conv1[0][0]               \n__________________________________________________________________________________________________\nblock4_conv3 (Conv2D)           (None, 45, 60, 512)  2359808     block4_conv2[0][0]               \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 23, 30, 512)  0           block4_conv3[0][0]               \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 23, 30, 1024) 4719616     max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 23, 30, 1024) 9438208     conv2d[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 23, 30, 1024) 4096        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 46, 60, 1024) 0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 46, 60, 512)  2097664     up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 45, 60, 512)  0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 45, 60, 1024) 0           lambda[0][0]                     \n                                                                 block4_conv3[0][0]               \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 45, 60, 512)  4719104     concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 45, 60, 512)  2359808     conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 45, 60, 512)  2359808     conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 45, 60, 512)  2048        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 90, 120, 512) 0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 90, 120, 256) 524544      up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 90, 120, 512) 0           conv2d_6[0][0]                   \n                                                                 block3_conv3[0][0]               \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 90, 120, 256) 1179904     concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 90, 120, 256) 590080      conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 90, 120, 256) 590080      conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 90, 120, 256) 1024        conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 180, 240, 256 0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 180, 240, 128 131200      up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 180, 240, 256 0           conv2d_10[0][0]                  \n                                                                 block2_conv2[0][0]               \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 180, 240, 128 295040      concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 180, 240, 128 147584      conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 180, 240, 128 147584      conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 180, 240, 128 512         conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 360, 480, 128 0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 360, 480, 64) 32832       up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 360, 480, 128 0           conv2d_14[0][0]                  \n                                                                 block1_conv2[0][0]               \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 360, 480, 64) 73792       concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 360, 480, 64) 36928       conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 360, 480, 12) 780         conv2d_16[0][0]                  \n==================================================================================================\nTotal params: 37,087,500\nTrainable params: 29,448,396\nNon-trainable params: 7,639,104\n__________________________________________________________________________________________________\nFound 367 validated image filenames.\nFound 367 validated image filenames.\nEpoch 1/5\n400/400 [==============================] - 88s 206ms/step - loss: 0.2407 - accuracy: 0.0264\nEpoch 2/5\n400/400 [==============================] - 81s 203ms/step - loss: 4.4707 - accuracy: 0.0664\nEpoch 3/5\n400/400 [==============================] - 81s 203ms/step - loss: 23.5771 - accuracy: 0.0659\nEpoch 4/5\n400/400 [==============================] - 81s 203ms/step - loss: 64.6216 - accuracy: 0.0664\nEpoch 5/5\n400/400 [==============================] - 81s 203ms/step - loss: 152.4057 - accuracy: 0.0773\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f5f8c120a50>"},"metadata":{}}]},{"cell_type":"code","source":"results = unet.predict(testgenerator(), steps=51)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 101 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"results.shape : \", results.shape)\nprint(\"Unique in 0th prediction : \", np.unique(results[0, :, :, :]))\nimg1 = np.argmax(results[0, :, :, :], axis=2)\nprint(\"0th prediction.shape : \", img1.shape)\nimg1 = np.reshape(img1, newshape=(360, 480))\nprint(\"0th prediction.shape : \", img1.shape)\nplt.imshow(img1)\nplt.show()\nprint(\"Unique in 0th prediction : \", np.unique(img1))","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"results.shape :  (101, 360, 480, 12)\nUnique in 0th prediction :  [0.00000000e+00 2.71348444e-38 4.47377931e-38 3.30570052e-37\n 2.44260071e-36 1.80485147e-35 1.33361487e-34 5.97684694e-34\n 9.85415445e-34 2.67863681e-33 7.28129045e-33 1.97925992e-32\n 3.26324784e-32 5.38018651e-32 8.87042672e-32 3.97544995e-31\n 1.08063920e-30 2.93748195e-30 7.98490480e-30 2.17052199e-29\n 1.60381082e-28 4.35961013e-28 8.75651089e-27 2.38026637e-26\n 6.47023468e-26 4.78089300e-25 1.29958149e-24 3.53262839e-24\n 2.61027905e-23 1.92874977e-22 1.42516414e-21 2.34969821e-21\n 3.87399781e-21 1.05306175e-20 2.86251861e-20 7.78113228e-20\n 5.74952202e-19 4.24835413e-18 3.13913256e-17 8.53304829e-17\n 2.31952270e-16 1.71390849e-15 4.65888577e-15 1.26641649e-14\n 9.35762291e-14 2.54366569e-13 6.91440015e-13 5.10908893e-12\n 1.38879429e-11 1.02618795e-10 2.78946810e-10 2.06115347e-09\n 1.52299791e-08 1.12534465e-07 8.31528041e-07 1.37095719e-06\n 6.14417377e-06 6.14417422e-06 1.01299902e-05 4.53978682e-05\n 3.35350138e-04 2.47262302e-03 1.79862101e-02 1.19202919e-01\n 2.68941432e-01 5.00000000e-01 7.31058598e-01 8.80797029e-01\n 9.82013762e-01 9.97527421e-01 9.99664664e-01 9.99954581e-01\n 9.99989867e-01 9.99993682e-01 9.99993801e-01 9.99998569e-01\n 9.99999166e-01 1.00000000e+00]\n0th prediction.shape :  (360, 480)\n0th prediction.shape :  (360, 480)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"Unique in 0th prediction :  [ 0  1  3  4  6  9 10]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}